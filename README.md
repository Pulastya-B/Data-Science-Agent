# Data Science Copilot ğŸ¤–

An AI-powered CLI tool that automates end-to-end data science workflows using Groq's GPT-OSS-120B. Think "Cursor for Data Science" - an intelligent agent that profiles data, cleans datasets, engineers features, and trains models autonomously.

## ğŸ¯ Project Goal

Achieve **50-70th percentile performance** on Kaggle competitions through intelligent automation of data science workflows, proving that AI agents can handle real-world ML tasks end-to-end.

## âœ¨ Features

### Intelligent Orchestration
- **Native Groq Function Calling**: Direct integration with Groq's GPT-OSS-120B (no frameworks)
- **Smart Routing**: LLM intelligently selects and chains tools based on task requirements
- **Adaptive Workflows**: Automatically adjusts strategy based on data characteristics
- **Context-Aware**: Remembers previous steps and learns from tool outputs

### Comprehensive Tool Suite

#### ğŸ“Š Data Profiling
- `profile_dataset`: Complete dataset statistics, types, memory usage
- `detect_data_quality_issues`: Outlier detection, duplicates, inconsistencies
- `analyze_correlations`: Feature relationships and target correlations

#### ğŸ§¹ Data Cleaning
- `clean_missing_values`: Smart imputation (median/mean/mode/forward_fill)
- `handle_outliers`: IQR-based detection with clip/winsorize/remove
- `fix_data_types`: Auto-detect and fix incorrect types

#### ğŸ”§ Feature Engineering
- `create_time_features`: Extract temporal patterns (cyclical encoding)
- `encode_categorical`: One-hot, target, and frequency encoding

#### ğŸ¤– Model Training
- `train_baseline_models`: Train and compare LR, RF, XGBoost
- `generate_model_report`: Metrics, feature importance, SHAP values

### Performance Optimization
- **SQLite Caching**: Memoization of expensive operations
- **Polars & DuckDB**: Fast data processing
- **Parallel Execution**: Independent tools run concurrently
- **Streaming Responses**: Real-time LLM output

## ğŸš€ Quick Start

### Prerequisites
- Python 3.9+
- Groq API key ([Get one here](https://console.groq.com))

### Installation

```bash
# Clone the repository
cd datascience-copilot

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Unix/MacOS:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env
# Edit .env and add your GROQ_API_KEY
```

### Basic Usage

```bash
# Complete analysis workflow
python src/cli.py analyze data.csv --target Survived --task "Predict survival"

# Quick profile
python src/cli.py profile data.csv

# Clean dataset
python src/cli.py clean data.csv --output cleaned_data.csv

# Train models
python src/cli.py train cleaned_data.csv Survived --task-type classification

# Cache management
python src/cli.py cache-stats
python src/cli.py clear-cache
```

### Example Workflow

```python
from src.orchestrator import DataScienceCopilot

# Initialize
copilot = DataScienceCopilot(reasoning_effort="medium")

# Run complete workflow
result = copilot.analyze(
    file_path="titanic.csv",
    task_description="Predict passenger survival with feature engineering",
    target_col="Survived"
)

print(result["summary"])
print(f"Best Model: {result['workflow_history']}")
```

See `examples/titanic_example.py` for a complete example.

## ğŸ—ï¸ Architecture

### Design Philosophy
- **No Frameworks**: Pure Groq SDK function calling (NO LangChain/CrewAI/LangGraph)
- **Single Orchestrator**: One intelligent router instead of multi-agent complexity
- **Fast Iteration**: Optimize for debugging and rapid development
- **Actionable Results**: Every tool returns structured, LLM-parseable outputs

### System Flow

```
User Query
    â†“
Orchestrator (GPT-OSS-120B)
    â†“
Function Calling Decision
    â†“
Tool Execution (Parallel where possible)
    â†“
Result Synthesis
    â†“
Final Recommendations
```

### Tech Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| LLM | Groq GPT-OSS-120B | Function calling & reasoning |
| Data Processing | Polars | Fast dataframe operations |
| SQL Operations | DuckDB | Complex queries |
| ML Libraries | scikit-learn, XGBoost | Model training |
| Hyperparameter Tuning | Optuna | Optimization |
| Explainability | SHAP | Feature importance |
| Caching | SQLite | Memoization |
| CLI | Typer + Rich | User interface |

## ğŸ“ Project Structure

```
datascience-copilot/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ orchestrator.py          # Main DataScienceCopilot class
â”‚   â”œâ”€â”€ cli.py                   # CLI interface
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ data_profiling.py    # Dataset analysis tools
â”‚   â”‚   â”œâ”€â”€ data_cleaning.py     # Cleaning & preprocessing
â”‚   â”‚   â”œâ”€â”€ feature_engineering.py # Feature creation
â”‚   â”‚   â”œâ”€â”€ model_training.py    # ML training & evaluation
â”‚   â”‚   â””â”€â”€ tools_registry.py    # Groq function definitions
â”‚   â”œâ”€â”€ cache/
â”‚   â”‚   â””â”€â”€ cache_manager.py     # SQLite caching
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ polars_helpers.py    # Data manipulation utilities
â”‚       â””â”€â”€ validation.py        # Input validation
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ titanic_example.py       # Complete workflow demo
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_tools.py
â”‚   â””â”€â”€ test_orchestrator.py
â”œâ”€â”€ data/                         # Test datasets
â”œâ”€â”€ outputs/                      # Generated outputs
â”‚   â”œâ”€â”€ models/                   # Trained models
â”‚   â”œâ”€â”€ reports/                  # Analysis reports
â”‚   â””â”€â”€ data/                     # Cleaned datasets
â”œâ”€â”€ cache_db/                     # SQLite cache
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

## ğŸ”§ Configuration

Edit `.env` file:

```env
# Groq API
GROQ_API_KEY=your_api_key_here
GROQ_MODEL=openai/gpt-oss-120b
REASONING_EFFORT=medium  # low, medium, high

# Cache
CACHE_DB_PATH=./cache_db/cache.db
CACHE_TTL_SECONDS=86400  # 24 hours

# Performance
MAX_PARALLEL_TOOLS=5
MAX_RETRIES=3
TIMEOUT_SECONDS=300
```

## ğŸ“Š Example Outputs

### Dataset Profile
```json
{
  "shape": {"rows": 891, "columns": 12},
  "memory_usage": {"total_mb": 0.08},
  "column_types": {
    "numeric": ["Age", "Fare", "SibSp", "Parch"],
    "categorical": ["Sex", "Embarked", "Cabin"],
    "datetime": []
  },
  "overall_stats": {
    "null_percentage": 19.87,
    "duplicate_rows": 0
  }
}
```

### Model Training Results
```json
{
  "best_model": {
    "name": "xgboost",
    "score": 0.8156,
    "model_path": "./outputs/models/xgboost.pkl"
  },
  "models": {
    "xgboost": {
      "test_metrics": {
        "accuracy": 0.8156,
        "f1": 0.7692,
        "precision": 0.7879,
        "recall": 0.7527
      }
    }
  }
}
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/

# Run with coverage
pytest --cov=src tests/

# Run specific test file
pytest tests/test_tools.py -v
```

## ğŸ“ Learning Resources

### Understanding the Architecture

**Why No Frameworks?**
- Direct control over function calling behavior
- Easier debugging and iteration
- Faster execution (no abstraction overhead)
- Better understanding of LLM capabilities

**Why Groq?**
- Extremely fast inference (LPU architecture)
- Native function calling support
- Cost-effective for high-volume usage
- `reasoning_effort` parameter for quality control

**Why Polars over Pandas?**
- 10-100x faster for large datasets
- Better memory efficiency
- Native parallelization
- Lazy evaluation

### Key Concepts

1. **Function Calling**: LLM decides which tools to use and with what parameters
2. **Tool Chaining**: Output of one tool becomes input for next
3. **Caching**: Avoid re-computing expensive operations
4. **Streaming**: Show progress in real-time

## ğŸ”® Roadmap

### Phase 2: Advanced Features
- [ ] Optuna hyperparameter tuning integration
- [ ] AutoML model selection
- [ ] Cross-validation strategies
- [ ] Ensemble methods

### Phase 3: Kaggle Integration
- [ ] Direct Kaggle API integration
- [ ] Automated submission pipeline
- [ ] Competition-specific strategies
- [ ] Leaderboard tracking

### Phase 4: Production Features
- [ ] REST API server
- [ ] Web UI dashboard
- [ ] Multi-dataset workflows
- [ ] Collaborative features

## ğŸ¤ Contributing

Contributions welcome! Areas for improvement:

1. **More Tools**: Time series, NLP preprocessing, image features
2. **Better Prompts**: Improve LLM reasoning quality
3. **Performance**: Optimize tool execution speed
4. **Tests**: Increase coverage
5. **Documentation**: More examples and tutorials

## ğŸ“ License

MIT License - see LICENSE file for details

## ğŸ™ Acknowledgments

- Groq for blazing-fast LLM inference
- Polars team for incredible data processing library
- Kaggle community for datasets and competitions
- OpenAI for function calling paradigm

## ğŸ“§ Support

- Issues: [GitHub Issues](https://github.com/yourusername/datascience-copilot/issues)
- Discussions: [GitHub Discussions](https://github.com/yourusername/datascience-copilot/discussions)

---

**Built with â¤ï¸ for the data science community**

*"Making data science accessible through AI automation"*
